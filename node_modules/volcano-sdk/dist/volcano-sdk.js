// src/volcano-sdk.ts
import { Client as MCPClient } from "@modelcontextprotocol/sdk/client/index.js";
import { StreamableHTTPClientTransport } from "@modelcontextprotocol/sdk/client/streamableHttp.js";
import { llmOpenAI as llmOpenAIProvider, llmOpenAIResponses as llmOpenAIResponsesProvider } from "./llms/openai.js";
import { executeParallel, executeBranch, executeSwitch, executeWhile, executeForEach, executeRetryUntil, executeRunAgent } from "./patterns.js";
import { createHash } from "node:crypto";
export { llmAnthropic } from "./llms/anthropic.js";
export { llmLlama } from "./llms/llama.js";
export { llmMistral } from "./llms/mistral.js";
export { llmBedrock } from "./llms/bedrock.js";
export { llmVertexStudio } from "./llms/vertex-studio.js";
export { llmAzure } from "./llms/azure.js";
export { createVolcanoTelemetry, noopTelemetry } from "./telemetry.js";
import Ajv from "ajv";
export const llmOpenAI = llmOpenAIProvider;
export const llmOpenAIResponses = llmOpenAIResponsesProvider;
export class VolcanoError extends Error {
    constructor(message, meta = {}, options) {
        super(message);
        this.name = this.constructor.name;
        this.meta = meta;
        if (options?.cause)
            this.cause = options.cause;
    }
}
export class AgentConcurrencyError extends VolcanoError {
}
export class TimeoutError extends VolcanoError {
}
export class ValidationError extends VolcanoError {
}
export class RetryExhaustedError extends VolcanoError {
}
export class LLMError extends VolcanoError {
}
export class MCPError extends VolcanoError {
}
export class MCPConnectionError extends MCPError {
}
export class MCPToolError extends MCPError {
}
function isRetryableStatus(status) {
    if (!status && status !== 0)
        return false;
    return status >= 500 || status === 429 || status === 408;
}
function classifyProviderFromLlm(usedLlm) {
    if (!usedLlm)
        return undefined;
    if (usedLlm.id)
        return `llm:${usedLlm.id}`;
    return `llm:${usedLlm.model}`;
}
function classifyProviderFromMcp(handle) {
    if (!handle)
        return undefined;
    try {
        const u = new URL(handle.url);
        return `mcp:${u.host}`;
    }
    catch {
        return `mcp:${handle.id}`;
    }
}
function normalizeError(e, kind, meta) {
    if (kind === 'timeout')
        return new TimeoutError(e?.message || 'Step timed out', { ...meta, retryable: true }, { cause: e });
    if (kind === 'validation')
        return new ValidationError(e?.message || 'Validation failed', { ...meta, retryable: false }, { cause: e });
    if (kind === 'retry')
        return new RetryExhaustedError(e?.message || 'Retry attempts exhausted', { ...meta }, { cause: e });
    if (kind === 'llm') {
        const status = e?.status ?? e?.response?.status;
        const requestId = e?.response?.headers?.get?.('x-request-id') || e?.id || e?.response?.data?.id;
        const retryable = (status == null ? true : isRetryableStatus(status)) || !!e?.code?.toString?.()?.includes?.('ECONN') || !!e?.code?.toString?.()?.includes?.('ETIMEDOUT');
        return new LLMError(e?.message || 'LLM error', { ...meta, requestId, retryable }, { cause: e });
    }
    if (kind === 'mcp-conn') {
        const retryable = true;
        return new MCPConnectionError(e?.message || 'MCP connection error', { ...meta, retryable }, { cause: e });
    }
    // mcp-tool
    return new MCPToolError(e?.message || 'MCP tool error', { ...meta, retryable: false }, { cause: e });
}
/**
 * Connect to an MCP (Model Context Protocol) server via HTTP.
 * Supports connection pooling, OAuth/Bearer authentication, and automatic reconnection.
 *
 * @param url - HTTP endpoint URL for the MCP server (e.g., "http://localhost:3000/mcp")
 * @param options - Optional authentication configuration (OAuth 2.1 or Bearer token)
 * @returns MCPHandle for listing and calling tools
 *
 * @example
 * // Basic usage
 * const weather = mcp("http://localhost:3000/mcp");
 * const tools = await weather.listTools();
 * const forecast = await weather.callTool("get_forecast", { city: "San Francisco" });
 *
 * @example
 * // With OAuth authentication
 * const github = mcp("https://api.github.com/mcp", {
 *   auth: {
 *     type: 'oauth',
 *     clientId: process.env.GITHUB_CLIENT_ID!,
 *     clientSecret: process.env.GITHUB_SECRET!,
 *     tokenUrl: 'https://github.com/login/oauth/access_token'
 *   }
 * });
 */
export function mcp(url, options) {
    // Use hash-based ID to keep tool names under OpenAI's 64-char limit
    // Tool names are: ${id}.${toolName}, so short ID = more room for tool names
    const hash = createHash('md5').update(url).digest('hex').substring(0, 8);
    const id = `mcp_${hash}`; // e.g., "mcp_f3c8a9b1" (12 chars, deterministic)
    return {
        id,
        url,
        auth: options?.auth,
        listTools: async () => {
            return withMCP({ id, url, auth: options?.auth }, (c) => c.listTools());
        },
        callTool: async (name, args) => {
            return withMCP({ id, url, auth: options?.auth }, (c) => c.callTool({ name, arguments: args }));
        }
    };
}
// Ajv validator instance
const ajv = new Ajv({ allErrors: true, strict: false });
const VALIDATOR_CACHE = new WeakMap();
function validateWithSchema(schema, args, context) {
    if (!schema || typeof schema !== 'object')
        return; // nothing to validate
    let validate = VALIDATOR_CACHE.get(schema);
    if (!validate) {
        validate = ajv.compile(schema);
        VALIDATOR_CACHE.set(schema, validate);
    }
    const ok = validate(args);
    if (!ok) {
        const msg = (validate.errors || []).map((e) => `${e.instancePath || e.schemaPath}: ${e.message}`).join('; ');
        throw new Error(`${context} arguments failed schema validation: ${msg}`);
    }
}
export function __internal_validateToolArgs(schema, args) { validateWithSchema(schema, args, 'test'); }
const MCP_POOL = new Map();
let MCP_POOL_MAX = 16;
let MCP_POOL_IDLE_MS = 30000;
const OAUTH_TOKEN_CACHE = new Map();
async function getOAuthToken(auth, endpoint) {
    // Check cache first
    const cached = OAUTH_TOKEN_CACHE.get(endpoint);
    if (cached && cached.expiresAt > Date.now() + 60000) { // 60s buffer before expiration
        return cached.token;
    }
    // Acquire new token
    if (!auth.tokenEndpoint || !auth.clientId || !auth.clientSecret) {
        throw new Error(`OAuth auth requires tokenEndpoint, clientId, and clientSecret`);
    }
    // OAuth 2.0 RFC 6749 requires application/x-www-form-urlencoded for token requests
    const params = new URLSearchParams({
        grant_type: 'client_credentials',
        client_id: auth.clientId,
        client_secret: auth.clientSecret
    });
    // Add scope if provided (some OAuth servers require it)
    if (auth.scope) {
        params.set('scope', auth.scope);
    }
    const response = await fetch(auth.tokenEndpoint, {
        method: 'POST',
        headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
        body: params.toString()
    });
    if (!response.ok) {
        throw new Error(`OAuth token acquisition failed: ${response.status} ${await response.text()}`);
    }
    const data = await response.json();
    const token = data.access_token;
    const expiresIn = data.expires_in || 3600; // default 1 hour
    // Cache the token
    OAUTH_TOKEN_CACHE.set(endpoint, {
        token,
        expiresAt: Date.now() + (expiresIn * 1000)
    });
    return token;
}
async function getPooledClient(url, auth) {
    const poolKey = auth ? `${url}::auth` : url; // Separate pool entries for auth vs non-auth
    let entry = MCP_POOL.get(poolKey);
    if (!entry) {
        // Evict LRU idle if over max
        if (MCP_POOL.size >= MCP_POOL_MAX) {
            const idleEntries = Array.from(MCP_POOL.entries()).filter(([, e]) => e.busyCount === 0);
            idleEntries.sort((a, b) => a[1].lastUsed - b[1].lastUsed);
            const toEvict = idleEntries.slice(0, Math.max(0, MCP_POOL.size - MCP_POOL_MAX + 1));
            for (const [k, e] of toEvict) {
                try {
                    await e.client.close();
                }
                catch { }
                MCP_POOL.delete(k);
            }
        }
        // Create transport
        const transport = new StreamableHTTPClientTransport(new URL(url));
        const client = new MCPClient({ name: "volcano-sdk", version: "0.0.1" });
        // Connect with auth if needed
        if (auth) {
            await connectWithAuth(transport, client, auth, url);
        }
        else {
            await client.connect(transport);
        }
        entry = { client, transport, lastUsed: Date.now(), busyCount: 0, auth };
        MCP_POOL.set(poolKey, entry);
    }
    entry.busyCount++;
    entry.lastUsed = Date.now();
    return entry;
}
async function connectWithAuth(transport, client, auth, endpoint) {
    // Get auth headers
    const authHeaders = {};
    if (auth.type === 'oauth') {
        const token = await getOAuthToken(auth, endpoint);
        authHeaders['Authorization'] = `Bearer ${token}`;
    }
    else if (auth.type === 'bearer' && auth.token) {
        authHeaders['Authorization'] = `Bearer ${auth.token}`;
    }
    // Wrap fetch globally during connect
    const originalFetch = global.fetch;
    global.fetch = async (url, init = {}) => {
        let mergedHeaders = {};
        if (init.headers) {
            if (init.headers instanceof Headers) {
                init.headers.forEach((value, key) => {
                    mergedHeaders[key] = value;
                });
            }
            else {
                mergedHeaders = { ...init.headers };
            }
        }
        Object.assign(mergedHeaders, authHeaders);
        return originalFetch(url, {
            ...init,
            headers: mergedHeaders
        });
    };
    try {
        await client.connect(transport);
    }
    finally {
        global.fetch = originalFetch;
    }
}
async function cleanupIdlePool() {
    const now = Date.now();
    for (const [url, entry] of MCP_POOL) {
        if (entry.busyCount === 0 && now - entry.lastUsed > MCP_POOL_IDLE_MS) {
            try {
                await entry.client.close();
            }
            catch { }
            MCP_POOL.delete(url);
        }
    }
}
// Periodic cleanup
let POOL_SWEEPER = undefined;
function ensurePoolSweeper() {
    if (!POOL_SWEEPER) {
        POOL_SWEEPER = setInterval(() => { cleanupIdlePool(); }, 5000);
        // In tests or short-lived processes we don’t need to keep the event loop alive
        if (typeof POOL_SWEEPER.unref === 'function')
            POOL_SWEEPER.unref();
    }
}
// Internal test helpers
export function __internal_getMcpPoolStats() {
    return {
        size: MCP_POOL.size,
        entries: Array.from(MCP_POOL.entries()).map(([url, e]) => ({ url, busyCount: e.busyCount, lastUsed: e.lastUsed }))
    };
}
export async function __internal_forcePoolCleanup() { await cleanupIdlePool(); }
export function __internal_setPoolConfig(max, idleMs) { MCP_POOL_MAX = max; MCP_POOL_IDLE_MS = idleMs; }
export function __internal_clearOAuthTokenCache() { OAUTH_TOKEN_CACHE.clear(); }
export function __internal_getOAuthTokenCache() {
    return Array.from(OAUTH_TOKEN_CACHE.entries()).map(([endpoint, entry]) => ({
        endpoint,
        token: entry.token,
        expiresAt: entry.expiresAt
    }));
}
async function withMCP(h, fn, telemetry, operation) {
    ensurePoolSweeper();
    const poolKey = h.auth ? `${h.url}::auth` : h.url;
    const entry = await getPooledClient(h.url, h.auth);
    // Start MCP span if telemetry configured
    const mcpSpan = telemetry && operation ? telemetry.startMCPSpan(null, h, operation) : null;
    try {
        let result;
        // Always wrap with auth if configured (for both connect and tool calls)
        if (h.auth || entry.auth) {
            const authConfig = h.auth || entry.auth;
            result = await executeWithAuth(authConfig, h.url, () => fn(entry.client));
        }
        else {
            result = await fn(entry.client);
        }
        telemetry?.endSpan(mcpSpan);
        telemetry?.recordMetric('mcp.call', 1, { endpoint: h.url, error: false });
        return result;
    }
    catch (error) {
        telemetry?.endSpan(mcpSpan, undefined, error);
        telemetry?.recordMetric('mcp.call', 1, { endpoint: h.url, error: true });
        throw error;
    }
    finally {
        const e = MCP_POOL.get(poolKey);
        if (e) {
            e.busyCount = Math.max(0, e.busyCount - 1);
            e.lastUsed = Date.now();
        }
    }
}
async function executeWithAuth(auth, endpoint, fn) {
    // Get auth headers
    const authHeaders = {};
    if (auth.type === 'oauth') {
        const token = await getOAuthToken(auth, endpoint);
        authHeaders['Authorization'] = `Bearer ${token}`;
    }
    else if (auth.type === 'bearer' && auth.token) {
        authHeaders['Authorization'] = `Bearer ${auth.token}`;
    }
    // Wrap fetch
    const originalFetch = global.fetch;
    global.fetch = async (url, init = {}) => {
        let mergedHeaders = {};
        if (init.headers) {
            if (init.headers instanceof Headers) {
                init.headers.forEach((value, key) => {
                    mergedHeaders[key] = value;
                });
            }
            else {
                mergedHeaders = { ...init.headers };
            }
        }
        Object.assign(mergedHeaders, authHeaders);
        return originalFetch(url, {
            ...init,
            headers: mergedHeaders
        });
    };
    try {
        return await fn();
    }
    finally {
        global.fetch = originalFetch;
    }
}
function sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
}
function withTimeout(promise, ms, label = 'Step') {
    let timer;
    const timeout = new Promise((_, reject) => {
        timer = setTimeout(() => reject(new Error(`${label} timed out after ${ms}ms`)), ms);
    });
    return Promise.race([promise, timeout]).finally(() => clearTimeout(timer));
}
// Tool discovery cache for automatic selection
const TOOL_CACHE = new Map();
let TOOL_CACHE_TTL_MS = 60000;
/**
 * Discover all available tools from one or more MCP servers.
 * Results are cached for 60 seconds to improve performance.
 *
 * @param handles - Array of MCP handles to query for tools
 * @returns Combined array of all available tools from all servers
 *
 * @example
 * const weather = mcp("http://localhost:3000/mcp");
 * const calendar = mcp("http://localhost:4000/mcp");
 * const tools = await discoverTools([weather, calendar]);
 * console.log(tools.map(t => t.name)); // ["get_forecast", "create_event", ...]
 */
export async function discoverTools(handles) {
    const allTools = [];
    for (const handle of handles) {
        try {
            const cached = TOOL_CACHE.get(handle.url);
            if (cached && (Date.now() - cached.ts) < TOOL_CACHE_TTL_MS) {
                // reuse cached with endpoint-specific names
                allTools.push(...cached.tools);
                continue;
            }
            const tools = await withMCP(handle, async (client) => {
                const result = await client.listTools();
                const mapped = result.tools.map(tool => ({
                    name: `${handle.id}.${tool.name}`,
                    description: tool.description || `Tool: ${tool.name}`,
                    parameters: tool.inputSchema || { type: "object", properties: {} },
                    mcpHandle: handle,
                }));
                TOOL_CACHE.set(handle.url, { tools: mapped, ts: Date.now() });
                return mapped;
            });
            allTools.push(...tools);
        }
        catch (error) {
            // Invalidate cache on failure
            TOOL_CACHE.delete(handle.url);
            // Fail fast - throw connection error
            throw normalizeError(error, 'mcp-conn', {
                provider: classifyProviderFromMcp(handle),
                retryable: true // Connection errors are retryable
            });
        }
    }
    return allTools;
}
export function __internal_clearDiscoveryCache() { TOOL_CACHE.clear(); }
export function __internal_setDiscoveryTtl(ms) { TOOL_CACHE_TTL_MS = ms; }
export function __internal_primeDiscoveryCache(handle, rawTools) {
    const tools = rawTools.map(t => ({
        name: `${handle.id}.${t.name}`,
        description: t.description || `Tool: ${t.name}`,
        parameters: t.inputSchema || { type: 'object', properties: {} },
        mcpHandle: handle,
    }));
    TOOL_CACHE.set(handle.url, { tools, ts: Date.now() });
}
// helper to fetch tool schema for explicit calls
async function getToolSchema(handle, toolName) {
    const cached = TOOL_CACHE.get(handle.url);
    if (cached) {
        const found = cached.tools.find(t => t.name === `${handle.id}.${toolName}`);
        return found?.parameters;
    }
    try {
        const tools = await withMCP(handle, async (client) => {
            const result = await client.listTools();
            const mapped = result.tools.map(tool => ({
                name: `${handle.id}.${tool.name}`,
                description: tool.description || `Tool: ${tool.name}`,
                parameters: tool.inputSchema || { type: 'object', properties: {} },
                mcpHandle: handle,
            }));
            TOOL_CACHE.set(handle.url, { tools: mapped, ts: Date.now() });
            return mapped;
        });
        const found = tools.find(t => t.name === `${handle.id}.${toolName}`);
        return found?.parameters;
    }
    catch {
        return undefined;
    }
}
function buildHistoryContextChunked(history, maxToolResults, maxChars) {
    if (history.length === 0)
        return '';
    const chunks = [];
    // Include LLM output from last step
    const last = history[history.length - 1];
    if (last.llmOutput) {
        chunks.push('Previous LLM answer:\n');
        chunks.push(last.llmOutput);
        chunks.push('\n');
    }
    // Collect tool calls from ALL recent steps (not just last step)
    const allToolCalls = [];
    for (const step of history) {
        if (step.toolCalls && step.toolCalls.length > 0) {
            allToolCalls.push(...step.toolCalls);
        }
    }
    if (allToolCalls.length > 0) {
        chunks.push('Previous tool results:\n');
        // Take the most recent maxToolResults across ALL steps
        const recent = allToolCalls.slice(-maxToolResults);
        for (const t of recent) {
            chunks.push('- ');
            chunks.push(t.name);
            // Include arguments to preserve context like issue numbers, IDs, etc
            if (t.arguments) {
                try {
                    chunks.push('(');
                    chunks.push(JSON.stringify(t.arguments));
                    chunks.push(')');
                }
                catch {
                    // Skip if arguments can't be serialized
                }
            }
            chunks.push(' -> ');
            if (typeof t.result === 'string') {
                chunks.push(t.result);
            }
            else {
                try {
                    chunks.push(JSON.stringify(t.result));
                }
                catch {
                    chunks.push('[unserializable]');
                }
            }
            chunks.push('\n');
        }
    }
    // prefix header
    chunks.unshift('\n\n[Context from previous steps]\n');
    // assemble with maxChars cap
    let out = '';
    for (const c of chunks) {
        if (out.length + c.length > maxChars)
            break;
        out += c;
    }
    return out;
}
/**
 * Helper function to execute LLM generation with optional token streaming.
 * Handles both step-level and stream-level onToken callbacks with proper precedence.
 */
async function executeLLMWithStreaming(llm, prompt, stepOnToken, streamOnToken, meta) {
    const hasStepOnToken = !!stepOnToken;
    const effectiveOnToken = stepOnToken || streamOnToken;
    if (effectiveOnToken && typeof llm.genStream === 'function') {
        const tokens = [];
        const tokenMeta = {
            stepIndex: meta.stepIndex,
            handledByStep: hasStepOnToken,
            stepPrompt: meta.stepPrompt,
            llmProvider: llm.id || llm.model
        };
        for await (const token of llm.genStream(prompt)) {
            tokens.push(token);
            try {
                if (hasStepOnToken) {
                    stepOnToken(token);
                }
                else {
                    streamOnToken(token, tokenMeta);
                }
            }
            catch (e) {
                console.warn('onToken callback failed:', e);
            }
        }
        return tokens.join('');
    }
    else {
        return await llm.gen(prompt);
    }
}
/**
 * Shared display helpers for consistent progress formatting.
 */
const createProgressDisplay = (workflowStart, isTTY) => ({
    showWaiting: () => {
        console.log('\n   ⏳ Waiting for LLM');
    },
    showTokens: (count, provider) => {
        const elapsed = (Date.now() - workflowStart) / 1000;
        const throughput = Math.round(count / Math.max(elapsed, 0.1));
        const providerInfo = provider ? ` (via ${provider})` : '';
        if (count === 1) {
            // Clear waiting message (move up one line)
            process.stdout.write('\x1b[1A\r\x1b[K');
        }
        if (count % 10 === 0 || count === 1) {
            process.stdout.write(`\r   💭 ${count} tokens | ${throughput} tok/s${providerInfo}`);
        }
    },
    showComplete: (durationMs, tokens, provider) => {
        if (isTTY)
            process.stdout.write('\r\x1b[K');
        const providerInfo = provider ? ` | ${provider}` : '';
        console.log(`   ✅ Complete | ${tokens.toLocaleString()} token${tokens > 1 ? 's' : ''} | ${(durationMs / 1000).toFixed(1)}s${providerInfo}\n`);
    }
});
/**
 * Create beautiful TTY progress handler for workflows.
 */
function createProgressHandler(totalSteps, isSubAgent = false, isExplicitSubAgent = false, parentStepIndex, parentTotalSteps) {
    const workflowStart = Date.now();
    const isTTY = process.stdout?.isTTY || false;
    const display = createProgressDisplay(workflowStart, isTTY);
    let operationStart = Date.now();
    let waitInterval = null;
    if (!isSubAgent) {
        console.log('\n🌋 Running Volcano agent [volcano-sdk v1.0.1] • docs at https://volcano.dev');
        console.log('━'.repeat(50));
    }
    return {
        stepStart: (stepIndex, prompt) => {
            // For agent crews (delegated agents), suppress step start (parent shows delegation)
            if (isSubAgent && !isExplicitSubAgent)
                return;
            // For explicit sub-agents, use parent step numbering
            const display = prompt?.substring(0, 60) || 'Processing';
            const actualStepNum = (isExplicitSubAgent && parentStepIndex !== undefined) ? parentStepIndex + stepIndex + 1 : stepIndex + 1;
            const actualTotalSteps = (isExplicitSubAgent && parentTotalSteps !== undefined) ? parentTotalSteps : totalSteps;
            console.log(`🤖 Step ${actualStepNum}/${actualTotalSteps}: ${display}${prompt && prompt.length > 60 ? '...' : ''}`);
        },
        startLlmOperation: () => {
            operationStart = Date.now();
            // Show elapsed time while waiting for first token
            if (isTTY && !isSubAgent) {
                waitInterval = setInterval(() => {
                    const elapsed = ((Date.now() - operationStart) / 1000).toFixed(1);
                    process.stdout.write(`\r   ⏳ Waiting for LLM | ${elapsed}s`);
                }, 100);
            }
        },
        llmToken: (count, provider) => {
            // For agent crews, suppress token progress (parent tracks via onToken callback)
            // For explicit sub-agents, show token progress
            if (isSubAgent && !isExplicitSubAgent)
                return;
            // Clear waiting interval on first token
            if (count === 1 && waitInterval) {
                clearInterval(waitInterval);
                waitInterval = null;
            }
            const elapsed = (Date.now() - operationStart) / 1000;
            const throughput = Math.round(count / Math.max(elapsed, 0.1));
            if (count % 10 === 0 || count === 1) {
                const providerInfo = provider ? ` | ${provider}` : '';
                process.stdout.write(`\r   💭 ${count} tokens | ${throughput} tok/s | ${elapsed.toFixed(1)}s${providerInfo}`);
            }
        },
        agentStart: (agentName, task) => {
            console.log(`\n⚡ ${agentName} → ${task.substring(0, 50)}...`);
            operationStart = Date.now();
            // Show elapsed time while waiting for first token
            if (isTTY) {
                waitInterval = setInterval(() => {
                    const elapsed = ((Date.now() - operationStart) / 1000).toFixed(1);
                    process.stdout.write(`\r   ⏳ Waiting for LLM | ${elapsed}s`);
                }, 100);
            }
            else {
                process.stdout.write('   ⏳ Waiting for LLM');
            }
        },
        agentToken: (count, provider) => {
            // Clear waiting interval on first token
            if (count === 1 && waitInterval) {
                clearInterval(waitInterval);
                waitInterval = null;
            }
            const elapsed = (Date.now() - operationStart) / 1000;
            const throughput = Math.round(count / Math.max(elapsed, 0.1));
            if (count % 10 === 0 || count === 1) {
                if (count === 1) {
                    // First token - clear the "Waiting..." line
                    process.stdout.write('\r\x1b[K');
                }
                const providerInfo = provider ? ` | ${provider}` : '';
                process.stdout.write(`\r   💭 ${count} tokens | ${throughput} tok/s | ${elapsed.toFixed(1)}s${providerInfo}`);
            }
        },
        agentComplete: (agentName, tokens, durationMs, provider) => {
            display.showComplete(durationMs, tokens, provider);
        },
        stepComplete: (durationMs, tokenCount, provider, crewTokens, crewModels) => {
            // For agent crews, suppress step complete (parent shows completion)
            // For explicit sub-agents, show step complete
            if (isSubAgent && !isExplicitSubAgent)
                return;
            if (crewTokens && crewModels) {
                // Crew workflow - don't show anything here, workflowEnd will show the final summary
                return;
            }
            else if (tokenCount) {
                display.showComplete(durationMs, tokenCount, provider);
            }
            else {
                if (isTTY)
                    process.stdout.write('\r\x1b[K');
                console.log(`   ✅ Complete | ${(durationMs / 1000).toFixed(1)}s\n`);
            }
        },
        workflowEnd: (stepCount, totalTokens, totalDuration, models) => {
            if (isSubAgent)
                return; // Suppress footer for sub-agents
            console.log('━'.repeat(50));
            if (totalTokens && models && models.length > 0) {
                const modelsList = models.join(', ');
                console.log(`🎉 Agent complete | ${totalTokens.toLocaleString()} tokens | ${((totalDuration || 0) / 1000).toFixed(1)}s | ${modelsList}`);
            }
            else {
                const total = (Date.now() - workflowStart) / 1000;
                console.log(`🎉 Workflow complete! ${stepCount} step${stepCount > 1 ? 's' : ''} in ${total.toFixed(1)}s`);
            }
        }
    };
}
/**
 * Build agent context string for multi-agent coordination.
 */
function buildAgentContext(agents) {
    const agentList = agents
        .filter(a => a.name && a.description)
        .map(a => `- ${a.name}: ${a.description}`)
        .join('\n');
    return `

Available agents to help you:
${agentList}

To delegate to an agent, respond with: USE [agent_name]: [specific task for that agent]
When you have the final answer, respond with: DONE: [your final answer]
`;
}
/**
 * Parse coordinator LLM response for agent delegation.
 */
function parseAgentDecision(response) {
    const useMatch = response.match(/USE\s+(\w+):\s*(.+?)(?=\n(?:USE|DONE:)|$)/s);
    if (useMatch) {
        return {
            type: 'use_agent',
            agentName: useMatch[1].trim(),
            task: useMatch[2].trim()
        };
    }
    const doneMatch = response.match(/DONE:\s*(.+)/s);
    if (doneMatch) {
        return {
            type: 'done',
            answer: doneMatch[1].trim()
        };
    }
    return {
        type: 'continue',
        raw: response
    };
}
/**
 * Create an AI agent that chains LLM reasoning with MCP tool calls.
 *
 * @param opts - Optional configuration including LLM provider, instructions, timeout, retry policy, and observability
 * @returns AgentBuilder for chaining steps with .then(), run(), and stream()
 *
 * @example
 * // Simple agent
 * const results = await agent({ llm: llmOpenAI({...}) })
 *   .then({ prompt: "Analyze data" })
 *   .then({ prompt: "Generate insights" })
 *   .run();
 *
 * @example
 * // With automatic tool selection
 * await agent({ llm })
 *   .then({
 *     prompt: "Book a meeting and send confirmation",
 *     mcps: [calendar, email]
 *   })
 *   .run();
 */
export function agent(opts) {
    const steps = [];
    const defaultLlm = opts?.llm;
    let contextHistory = [];
    const globalInstructions = opts?.instructions;
    const agentName = opts?.name;
    const agentDescription = opts?.description;
    const showProgress = !opts?.hideProgress; // Progress enabled by default
    const defaultTimeoutMs = ((typeof opts?.timeout === 'number' ? opts.timeout : 60)) * 1000; // seconds -> ms
    const defaultRetry = opts?.retry ?? { delay: 0, retries: 3 };
    const contextMaxChars = typeof opts?.contextMaxChars === 'number' ? opts.contextMaxChars : 20480;
    const contextMaxToolResults = typeof opts?.contextMaxToolResults === 'number' ? opts.contextMaxToolResults : 8;
    const agentMcpAuth = opts?.mcpAuth || {};
    const telemetry = opts?.telemetry;
    const defaultMaxToolIterations = typeof opts?.maxToolIterations === 'number' ? opts.maxToolIterations : 4;
    let isRunning = false;
    // Helper to apply agent-level auth to MCP handle
    function applyAgentAuth(handle) {
        if (handle.auth)
            return handle; // Handle-level auth takes precedence
        const authConfig = agentMcpAuth[handle.url];
        if (authConfig) {
            return { ...handle, auth: authConfig };
        }
        return handle;
    }
    const builder = {
        name: agentName,
        description: agentDescription,
        resetHistory() { steps.push({ __reset: true }); return builder; },
        then(s) { steps.push(s); return builder; },
        // Parallel execution
        parallel(stepsOrDict, hooks) {
            steps.push({ __parallel: stepsOrDict, __hooks: hooks });
            return builder;
        },
        // Conditional branching
        branch(condition, branches, hooks) {
            steps.push({ __branch: { condition, branches }, __hooks: hooks });
            return builder;
        },
        switch(selector, cases, hooks) {
            steps.push({ __switch: { selector, cases }, __hooks: hooks });
            return builder;
        },
        // Loops
        while(condition, body, opts) {
            steps.push({ __while: { condition, body, opts } });
            return builder;
        },
        forEach(items, body, hooks) {
            steps.push({ __forEach: { items, body }, __hooks: hooks });
            return builder;
        },
        retryUntil(body, successCondition, opts) {
            steps.push({ __retryUntil: { body, successCondition, opts } });
            return builder;
        },
        // Sub-agent composition
        runAgent(subAgent, hooks) {
            steps.push({ __runAgent: { subAgent }, __hooks: hooks });
            return builder;
        },
        async run(log) {
            if (isRunning) {
                throw new AgentConcurrencyError('This agent is already running. Create a new agent() instance for concurrent runs.');
            }
            isRunning = true;
            const isSubAgent = builder.__isSubAgent || false;
            const isExplicitSubAgent = builder.__isExplicitSubAgent || false;
            const parentStepIndex = builder.__parentStepIndex;
            const parentTotalSteps = builder.__parentTotalSteps;
            const progress = showProgress ? createProgressHandler(steps.length, isSubAgent, isExplicitSubAgent, parentStepIndex, parentTotalSteps) : null;
            // Start agent span
            const agentSpan = telemetry?.startAgentSpan(steps.length) || null;
            const out = [];
            try {
                // snapshot steps array to make run isolated from later .then() calls
                const planned = [...steps];
                for (const raw of planned) {
                    if (raw.__reset) {
                        contextHistory = [];
                        continue;
                    }
                    // Handle advanced pattern steps
                    if (raw.__parallel) {
                        const hooks = raw.__hooks;
                        try {
                            hooks?.pre?.();
                        }
                        catch (e) {
                            console.warn('Pre-hook failed for parallel:', e);
                        }
                        const parallelResult = await executeParallel(raw.__parallel, async (step) => {
                            const subAgent = agent(opts).then(step);
                            const results = await subAgent.run();
                            return results[0];
                        });
                        out.push(parallelResult);
                        contextHistory.push(parallelResult);
                        log?.(parallelResult, out.length - 1);
                        try {
                            hooks?.post?.();
                        }
                        catch (e) {
                            console.warn('Post-hook failed for parallel:', e);
                        }
                        continue;
                    }
                    if (raw.__branch) {
                        const { condition, branches } = raw.__branch;
                        const hooks = raw.__hooks;
                        try {
                            hooks?.pre?.();
                        }
                        catch (e) {
                            console.warn('Pre-hook failed for branch:', e);
                        }
                        const branchResults = await executeBranch(condition, branches, out, () => agent(opts));
                        out.push(...branchResults);
                        contextHistory.push(...branchResults);
                        branchResults.forEach((r, i) => log?.(r, out.length - branchResults.length + i));
                        try {
                            hooks?.post?.();
                        }
                        catch (e) {
                            console.warn('Post-hook failed for branch:', e);
                        }
                        continue;
                    }
                    if (raw.__switch) {
                        const { selector, cases } = raw.__switch;
                        const hooks = raw.__hooks;
                        try {
                            hooks?.pre?.();
                        }
                        catch (e) {
                            console.warn('Pre-hook failed for switch:', e);
                        }
                        const switchResults = await executeSwitch(selector, cases, out, () => agent(opts));
                        out.push(...switchResults);
                        contextHistory.push(...switchResults);
                        switchResults.forEach((r, i) => log?.(r, out.length - switchResults.length + i));
                        try {
                            hooks?.post?.();
                        }
                        catch (e) {
                            console.warn('Post-hook failed for switch:', e);
                        }
                        continue;
                    }
                    if (raw.__while) {
                        const { condition, body, opts: whileOpts } = raw.__while;
                        try {
                            whileOpts?.pre?.();
                        }
                        catch (e) {
                            console.warn('Pre-hook failed for while:', e);
                        }
                        const whileResults = await executeWhile(condition, body, out, () => agent(opts), whileOpts);
                        out.push(...whileResults);
                        contextHistory.push(...whileResults);
                        whileResults.forEach((r, i) => log?.(r, out.length - whileResults.length + i));
                        try {
                            whileOpts?.post?.();
                        }
                        catch (e) {
                            console.warn('Post-hook failed for while:', e);
                        }
                        continue;
                    }
                    if (raw.__forEach) {
                        const { items, body } = raw.__forEach;
                        const hooks = raw.__hooks;
                        try {
                            hooks?.pre?.();
                        }
                        catch (e) {
                            console.warn('Pre-hook failed for forEach:', e);
                        }
                        const forEachResults = await executeForEach(items, body, () => agent(opts));
                        out.push(...forEachResults);
                        contextHistory.push(...forEachResults);
                        forEachResults.forEach((r, i) => log?.(r, out.length - forEachResults.length + i));
                        try {
                            hooks?.post?.();
                        }
                        catch (e) {
                            console.warn('Post-hook failed for forEach:', e);
                        }
                        continue;
                    }
                    if (raw.__retryUntil) {
                        const { body, successCondition, opts: retryOpts } = raw.__retryUntil;
                        try {
                            retryOpts?.pre?.();
                        }
                        catch (e) {
                            console.warn('Pre-hook failed for retryUntil:', e);
                        }
                        const retryResults = await executeRetryUntil(body, successCondition, () => agent(opts), retryOpts);
                        out.push(...retryResults);
                        contextHistory.push(...retryResults);
                        retryResults.forEach((r, i) => log?.(r, out.length - retryResults.length + i));
                        try {
                            retryOpts?.post?.();
                        }
                        catch (e) {
                            console.warn('Post-hook failed for retryUntil:', e);
                        }
                        continue;
                    }
                    if (raw.__runAgent) {
                        const { subAgent } = raw.__runAgent;
                        const hooks = raw.__hooks;
                        try {
                            hooks?.pre?.();
                        }
                        catch (e) {
                            console.warn('Pre-hook failed for runAgent:', e);
                        }
                        const subResults = await executeRunAgent(subAgent, out.length, planned.length);
                        out.push(...subResults);
                        contextHistory.push(...subResults);
                        subResults.forEach((r, i) => log?.(r, out.length - subResults.length + i));
                        try {
                            hooks?.post?.();
                        }
                        catch (e) {
                            console.warn('Post-hook failed for runAgent:', e);
                        }
                        continue;
                    }
                    const s = typeof raw === 'function' ? raw(out) : raw;
                    const stepTimeoutMs = s.timeout != null ? s.timeout * 1000 : defaultTimeoutMs; // seconds -> ms
                    const retryCfg = s.retry ?? defaultRetry;
                    const attemptsTotal = typeof retryCfg.retries === 'number' && retryCfg.retries > 0 ? retryCfg.retries : (defaultRetry.retries ?? 3);
                    const useDelay = typeof retryCfg.delay === 'number' ? retryCfg.delay : (defaultRetry.delay ?? 0);
                    const useBackoff = retryCfg.backoff;
                    if (useDelay && useBackoff)
                        throw new Error('retry: specify either delay or backoff, not both');
                    const doStep = async () => {
                        // Execute pre-step hook
                        if (s.pre) {
                            try {
                                s.pre();
                            }
                            catch (e) {
                                console.warn('Pre-step hook failed:', e);
                            }
                        }
                        // Determine step type for telemetry
                        let stepType = 'unknown';
                        if ("agents" in s)
                            stepType = 'agent_crew';
                        else if ("mcps" in s)
                            stepType = 'mcp_auto';
                        else if ("mcp" in s)
                            stepType = 'mcp_explicit';
                        else if ("prompt" in s)
                            stepType = 'llm';
                        // Start step span
                        const stepSpan = telemetry?.startStepSpan(agentSpan, out.length, stepType) || null;
                        const r = {};
                        const stepStart = Date.now();
                        if (progress)
                            progress.stepStart(out.length, s.prompt);
                        let llmTotalMs = 0;
                        // Automatic tool selection with iterative tool calls
                        if ("mcps" in s && "prompt" in s) {
                            const usedLlm = s.llm ?? defaultLlm;
                            if (!usedLlm)
                                throw new Error("No LLM provided. Pass { llm } to agent(...) or specify per-step.");
                            const stepInstructions = s.instructions ?? globalInstructions;
                            const cmr = s.contextMaxToolResults ?? contextMaxToolResults;
                            const cmc = s.contextMaxChars ?? contextMaxChars;
                            const promptWithHistory = s.prompt + buildHistoryContextChunked(contextHistory, cmr, cmc);
                            r.prompt = s.prompt;
                            // Apply agent-level auth to all MCP handles
                            const mcpsWithAuth = s.mcps.map(applyAgentAuth);
                            const availableTools = await discoverTools(mcpsWithAuth);
                            if (availableTools.length === 0) {
                                r.llmOutput = "No tools available for this request.";
                            }
                            else {
                                const aggregated = [];
                                const maxIterations = s.maxToolIterations ?? defaultMaxToolIterations;
                                let workingPrompt = (stepInstructions ? stepInstructions + "\n\n" : "") + promptWithHistory;
                                for (let i = 0; i < maxIterations; i++) {
                                    const llmStart = Date.now();
                                    let toolPlan;
                                    try {
                                        toolPlan = await usedLlm.genWithTools(workingPrompt, availableTools);
                                    }
                                    catch (e) {
                                        const provider = classifyProviderFromLlm(usedLlm);
                                        throw normalizeError(e, 'llm', { stepId: out.length, provider });
                                    }
                                    llmTotalMs += Date.now() - llmStart;
                                    if (!toolPlan || !Array.isArray(toolPlan.toolCalls) || toolPlan.toolCalls.length === 0) {
                                        // finish with final content
                                        r.llmOutput = toolPlan?.content || r.llmOutput;
                                        break;
                                    }
                                    // Execute tools sequentially and append results to prompt for the next iteration
                                    let toolResultsAppend = "\n\n[Tool results]\n";
                                    for (const call of toolPlan.toolCalls) {
                                        const mapped = call;
                                        let handle = mapped?.mcpHandle;
                                        if (!handle)
                                            continue;
                                        // Apply agent-level auth
                                        handle = applyAgentAuth(handle);
                                        // Validate args when schema known
                                        try {
                                            validateWithSchema(availableTools.find(t => t.name === mapped.name)?.parameters, mapped.arguments, `Tool ${mapped.name}`);
                                        }
                                        catch (e) {
                                            throw e;
                                        }
                                        const idx = mapped.name.indexOf('.');
                                        const actualToolName = idx >= 0 ? mapped.name.slice(idx + 1) : mapped.name;
                                        const mcpStart = Date.now();
                                        let result;
                                        try {
                                            result = await withMCP(handle, (c) => c.callTool({ name: actualToolName, arguments: mapped.arguments || {} }), telemetry, 'call_tool');
                                        }
                                        catch (e) {
                                            const provider = classifyProviderFromMcp(handle);
                                            throw normalizeError(e, 'mcp-tool', { stepId: out.length, provider });
                                        }
                                        const mcpMs = Date.now() - mcpStart;
                                        const toolCall = { name: mapped.name, arguments: mapped.arguments, endpoint: handle.url, result, ms: mcpMs };
                                        aggregated.push(toolCall);
                                        toolResultsAppend += `- ${mapped.name} -> ${typeof result === 'string' ? result : JSON.stringify(result)}\n`;
                                    }
                                    if (aggregated.length)
                                        r.toolCalls = aggregated;
                                    // Prepare next prompt with appended tool results
                                    workingPrompt = (stepInstructions ? stepInstructions + "\n\n" : "") + promptWithHistory + toolResultsAppend;
                                    // On next iteration, model can produce final answer or ask for more tools
                                }
                                // Ensure toolCalls is always set for automatic tool selection steps
                                if (!r.toolCalls)
                                    r.toolCalls = [];
                            }
                        }
                        // Automatic agent selection with iterative delegation
                        else if ("agents" in s && "prompt" in s) {
                            const usedLlm = s.llm ?? defaultLlm;
                            if (!usedLlm)
                                throw new Error("No LLM provided. Pass { llm } to agent(...) or specify per-step.");
                            const stepInstructions = s.instructions ?? globalInstructions;
                            const cmr = s.contextMaxToolResults ?? contextMaxToolResults;
                            const cmc = s.contextMaxChars ?? contextMaxChars;
                            const promptWithHistory = s.prompt + buildHistoryContextChunked(contextHistory, cmr, cmc);
                            r.prompt = s.prompt;
                            const availableAgents = s.agents;
                            if (availableAgents.length === 0 || !availableAgents.some(a => a.name && a.description)) {
                                r.llmOutput = "No agents available or agents missing name/description.";
                            }
                            else {
                                const agentContext = buildAgentContext(availableAgents);
                                const maxIterations = s.maxAgentIterations ?? defaultMaxToolIterations;
                                let workingPrompt = (stepInstructions ? stepInstructions + "\n\n" : "") + promptWithHistory + agentContext;
                                const agentCalls = [];
                                let totalTokens = 0;
                                const modelsUsed = new Set();
                                for (let i = 0; i < maxIterations; i++) {
                                    // Show coordinator thinking
                                    if (progress) {
                                        if (i === 0) {
                                            process.stdout.write('\n🧠 Coordinator selecting agents...\n');
                                            process.stdout.write("   ⏳ Waiting for LLM..");
                                        }
                                        else {
                                            process.stdout.write('🧠 Coordinator deciding next step...\n');
                                            process.stdout.write("   ⏳ Waiting for LLM..");
                                        }
                                        progress.startLlmOperation();
                                    }
                                    const llmStart = Date.now();
                                    let coordinatorResponse;
                                    let coordTokenCount = 0;
                                    try {
                                        // Use streaming for coordinator when progress enabled
                                        if (progress && typeof usedLlm.genStream === 'function') {
                                            const tokens = [];
                                            for await (const token of usedLlm.genStream(workingPrompt)) {
                                                tokens.push(token);
                                                coordTokenCount++;
                                                progress.llmToken(coordTokenCount, usedLlm.id || usedLlm.model);
                                            }
                                            coordinatorResponse = tokens.join('');
                                        }
                                        else {
                                            coordinatorResponse = await usedLlm.gen(workingPrompt);
                                        }
                                    }
                                    catch (e) {
                                        const provider = classifyProviderFromLlm(usedLlm);
                                        throw normalizeError(e, 'llm', { stepId: out.length, provider });
                                    }
                                    llmTotalMs += Date.now() - llmStart;
                                    const decision = parseAgentDecision(coordinatorResponse);
                                    if (decision.type === 'done') {
                                        totalTokens += coordTokenCount;
                                        modelsUsed.add(usedLlm.id || usedLlm.model);
                                        if (progress) {
                                            const coordTime = (Date.now() - llmStart) / 1000;
                                            // Clear token line and coordinator status line, then print decision
                                            process.stdout.write('\r\x1b[K'); // Clear token line
                                            process.stdout.write('\x1b[1A\r\x1b[K'); // Move up and clear coordinator status line
                                            if (i === 0) {
                                                process.stdout.write('🧠 Coordinator: Final answer ready\n');
                                            }
                                            else {
                                                process.stdout.write('🧠 Coordinator: Final answer ready\n');
                                            }
                                            process.stdout.write(`   ✅ Complete | ${coordTokenCount} tokens | ${coordTime.toFixed(1)}s | ${usedLlm.id || usedLlm.model}\n`);
                                        }
                                        r.llmOutput = decision.answer;
                                        break;
                                    }
                                    else if (decision.type === 'use_agent') {
                                        totalTokens += coordTokenCount;
                                        modelsUsed.add(usedLlm.id || usedLlm.model);
                                        if (progress) {
                                            const coordTime = (Date.now() - llmStart) / 1000;
                                            // Clear token line and coordinator status line, then print decision
                                            process.stdout.write('\r\x1b[K'); // Clear token line
                                            process.stdout.write('\x1b[1A\r\x1b[K'); // Move up and clear coordinator status line
                                            if (i === 0) {
                                                process.stdout.write(`🧠 Coordinator decision: USE ${decision.agentName}\n`);
                                            }
                                            else {
                                                process.stdout.write(`🧠 Coordinator decision: USE ${decision.agentName}\n`);
                                            }
                                            process.stdout.write(`   ✅ Complete | ${coordTokenCount} tokens | ${coordTime.toFixed(1)}s | ${usedLlm.id || usedLlm.model}\n`);
                                        }
                                        const selectedAgent = availableAgents.find(a => a.name === decision.agentName);
                                        if (!selectedAgent) {
                                            workingPrompt += `\n\nError: Agent '${decision.agentName}' not found. Available: ${availableAgents.map(a => a.name).join(', ')}`;
                                            continue;
                                        }
                                        if (progress)
                                            progress.agentStart(decision.agentName, decision.task);
                                        const agentStart = Date.now();
                                        let agentResult;
                                        let agentTokenCount = 0;
                                        try {
                                            // Pass onToken to agent for progress tracking
                                            const agentStep = { prompt: decision.task };
                                            if (progress) {
                                                agentStep.onToken = () => {
                                                    agentTokenCount++;
                                                    progress.agentToken(agentTokenCount, decision.agentName);
                                                };
                                            }
                                            // Mark delegated agent as sub-agent to suppress its progress banner
                                            const delegatedAgent = selectedAgent.then(agentStep);
                                            delegatedAgent.__isSubAgent = true;
                                            agentResult = await delegatedAgent.run();
                                        }
                                        catch (e) {
                                            workingPrompt += `\n\nAgent '${decision.agentName}' failed: ${e.message}`;
                                            continue;
                                        }
                                        const agentMs = Date.now() - agentStart;
                                        totalTokens += agentTokenCount;
                                        modelsUsed.add(usedLlm.id || usedLlm.model);
                                        const agentOutput = agentResult[agentResult.length - 1]?.llmOutput || '[no output]';
                                        agentCalls.push({ name: decision.agentName, task: decision.task, result: agentOutput });
                                        if (progress)
                                            progress.agentComplete(decision.agentName, agentTokenCount, agentMs, usedLlm.id || usedLlm.model);
                                        workingPrompt += `\n\nAgent '${decision.agentName}' completed (${agentMs}ms):\n${agentOutput}\n\nWhat's next?`;
                                    }
                                    else {
                                        if (i === maxIterations - 1) {
                                            r.llmOutput = decision.raw;
                                        }
                                        else {
                                            workingPrompt += `\n\nPlease use the USE or DONE directive.`;
                                        }
                                    }
                                }
                                if (!r.llmOutput && agentCalls.length > 0) {
                                    r.llmOutput = agentCalls[agentCalls.length - 1].result;
                                }
                                if (agentCalls.length > 0) {
                                    r.agentCalls = agentCalls;
                                    r.__crewTotalTokens = totalTokens;
                                    r.__crewModels = Array.from(modelsUsed);
                                    telemetry?.recordMetric('agent.delegation', agentCalls.length, { agents: agentCalls.map(c => c.name).join(',') });
                                    for (const agentCall of agentCalls) {
                                        telemetry?.recordMetric('agent.call', 1, { agentName: agentCall.name });
                                    }
                                }
                            }
                        }
                        // LLM-only steps
                        else if ("prompt" in s && !("mcp" in s) && !("mcps" in s) && !("agents" in s)) {
                            const usedLlm = s.llm ?? defaultLlm;
                            if (!usedLlm)
                                throw new Error("No LLM provided. Pass { llm } to agent(...) or specify per-step.");
                            const stepInstructions = s.instructions ?? globalInstructions;
                            const cmr2 = s.contextMaxToolResults ?? contextMaxToolResults;
                            const cmc2 = s.contextMaxChars ?? contextMaxChars;
                            const promptWithHistory = s.prompt + buildHistoryContextChunked(contextHistory, cmr2, cmc2);
                            const finalPrompt = (stepInstructions ? stepInstructions + "\n\n" : "") + promptWithHistory;
                            r.prompt = s.prompt;
                            const llmSpan = telemetry?.startLLMSpan(stepSpan, usedLlm, finalPrompt) || null;
                            if (progress)
                                progress.startLlmOperation();
                            const llmStart = Date.now();
                            try {
                                let tokenCount = 0;
                                const customOnToken = s.onToken;
                                const progressOnToken = !customOnToken && progress ? () => {
                                    tokenCount++;
                                    progress.llmToken(tokenCount, usedLlm.id || usedLlm.model);
                                } : undefined;
                                r.llmOutput = await executeLLMWithStreaming(usedLlm, finalPrompt, customOnToken || progressOnToken, undefined, { stepIndex: out.length, stepPrompt: s.prompt });
                                r.__tokenCount = tokenCount;
                                r.__provider = usedLlm.id || usedLlm.model;
                                telemetry?.endSpan(llmSpan);
                                telemetry?.recordMetric('llm.call', 1, { provider: usedLlm.id || usedLlm.model, error: false });
                            }
                            catch (e) {
                                telemetry?.endSpan(llmSpan, undefined, e);
                                telemetry?.recordMetric('llm.call', 1, { provider: usedLlm.id || usedLlm.model, error: true });
                                telemetry?.recordMetric('error', 1, { type: 'llm', provider: usedLlm.id || usedLlm.model });
                                const provider = classifyProviderFromLlm(usedLlm);
                                throw normalizeError(e, 'llm', { stepId: out.length, provider });
                            }
                            llmTotalMs += Date.now() - llmStart;
                        }
                        // Explicit MCP tool calls (existing behavior)
                        else if ("mcp" in s && "tool" in s) {
                            // Apply agent-level auth
                            const mcpHandle = applyAgentAuth(s.mcp);
                            if ("prompt" in s) {
                                const usedLlm = s.llm ?? defaultLlm;
                                if (!usedLlm)
                                    throw new Error("No LLM provided. Pass { llm } to agent(...) or specify per-step.");
                                const stepInstructions = s.instructions ?? globalInstructions;
                                const cmr3 = s.contextMaxToolResults ?? contextMaxToolResults;
                                const cmc3 = s.contextMaxChars ?? contextMaxChars;
                                const promptWithHistory = s.prompt + buildHistoryContextChunked(contextHistory, cmr3, cmc3);
                                const finalPrompt = (stepInstructions ? stepInstructions + "\n\n" : "") + promptWithHistory;
                                r.prompt = s.prompt;
                                const llmStart = Date.now();
                                r.llmOutput = await usedLlm.gen(finalPrompt);
                                llmTotalMs += Date.now() - llmStart;
                            }
                            // Validate against tool schema if discoverable
                            const schema = await getToolSchema(mcpHandle, s.tool);
                            validateWithSchema(schema, s.args ?? {}, `Tool ${mcpHandle.id}.${s.tool}`);
                            const mcpStart = Date.now();
                            let res;
                            try {
                                res = await withMCP(mcpHandle, (c) => c.callTool({ name: s.tool, arguments: s.args ?? {} }), telemetry, 'call_tool');
                            }
                            catch (e) {
                                const provider = classifyProviderFromMcp(mcpHandle);
                                throw normalizeError(e, 'mcp-tool', { stepId: out.length, provider });
                            }
                            const mcpMs = Date.now() - mcpStart;
                            r.mcp = { endpoint: mcpHandle.url, tool: s.tool, result: res, ms: mcpMs };
                        }
                        r.llmMs = llmTotalMs;
                        r.durationMs = Date.now() - stepStart;
                        // End step span
                        telemetry?.endSpan(stepSpan, r);
                        telemetry?.recordMetric('step.duration', r.durationMs, { type: stepType });
                        // Execute post-step hook
                        if (s.post) {
                            try {
                                s.post();
                            }
                            catch (e) {
                                console.warn('Post-step hook failed:', e);
                            }
                        }
                        return r;
                    };
                    // Retry loop with per-attempt timeout
                    let lastError;
                    let result;
                    for (let attempt = 1; attempt <= attemptsTotal; attempt++) {
                        try {
                            const r = await withTimeout(doStep(), stepTimeoutMs, 'Step');
                            result = r;
                            break;
                        }
                        catch (e) {
                            // classify
                            const meta = { stepId: out.length };
                            let vErr;
                            if (e instanceof Error && /timed out/i.test(e.message)) {
                                vErr = normalizeError(e, 'timeout', meta);
                            }
                            else if (e instanceof ValidationError || /failed schema validation/i.test(String(e?.message || ''))) {
                                vErr = normalizeError(e, 'validation', meta);
                            }
                            else {
                                vErr = e;
                            }
                            lastError = vErr || e;
                            if (lastError instanceof VolcanoError && lastError.meta?.retryable === false) {
                                throw lastError; // abort retries immediately for non-retryable errors
                            }
                            if (attempt >= attemptsTotal)
                                break;
                            // schedule wait according to policy
                            if (typeof useBackoff === 'number' && useBackoff > 0) {
                                const baseMs = 1000; // start at 1s
                                const waitMs = baseMs * Math.pow(useBackoff, attempt - 1);
                                await sleep(waitMs);
                            }
                            else {
                                const waitMs = Math.max(0, (useDelay ?? 0) * 1000);
                                if (waitMs > 0)
                                    await sleep(waitMs);
                            }
                        }
                    }
                    if (!result)
                        throw (lastError instanceof VolcanoError ? lastError : new RetryExhaustedError('Retry attempts exhausted', { stepId: out.length }, { cause: lastError }));
                    const r = result;
                    if (progress) {
                        const crewTokens = r.__crewTotalTokens;
                        const crewModels = r.__crewModels;
                        progress.stepComplete(r.durationMs || 0, r.__tokenCount, r.__provider, crewTokens, crewModels);
                    }
                    log?.(r, out.length);
                    out.push(r);
                    contextHistory.push(r);
                }
                // Populate aggregated totals on the final step
                if (out.length > 0) {
                    const totalDuration = out.reduce((acc, s) => acc + (s.durationMs || 0), 0);
                    const totalLlm = out.reduce((acc, s) => acc + (s.llmMs || 0), 0);
                    const totalMcp = out.reduce((acc, s) => {
                        let accStep = acc;
                        if (s.mcp?.ms)
                            accStep += s.mcp.ms;
                        if (s.toolCalls)
                            accStep += s.toolCalls.reduce((a, t) => a + (t.ms || 0), 0);
                        return accStep;
                    }, 0);
                    const last = out[out.length - 1];
                    last.totalDurationMs = totalDuration;
                    last.totalLlmMs = totalLlm;
                    last.totalMcpMs = totalMcp;
                    // End agent span and record metrics
                    telemetry?.endSpan(agentSpan, last);
                    telemetry?.recordMetric('agent.duration', totalDuration, { steps: out.length });
                }
                return out;
            }
            catch (error) {
                // End agent span with error
                telemetry?.endSpan(agentSpan, undefined, error);
                telemetry?.recordMetric('error', 1, { type: 'agent', level: 'workflow' });
                throw error;
            }
            finally {
                if (progress) {
                    // Calculate totals for workflow end
                    const totalTokens = out.reduce((acc, s) => {
                        const stepTokens = s.__tokenCount || s.__crewTotalTokens || 0;
                        return acc + stepTokens;
                    }, 0);
                    const modelsUsed = new Set();
                    out.forEach(s => {
                        const provider = s.__provider;
                        const crewModels = s.__crewModels;
                        if (provider)
                            modelsUsed.add(provider);
                        if (crewModels)
                            crewModels.forEach((m) => modelsUsed.add(m));
                    });
                    const totalDuration = out.reduce((acc, s) => acc + (s.durationMs || 0), 0);
                    progress.workflowEnd(steps.length, totalTokens, totalDuration, Array.from(modelsUsed));
                }
                isRunning = false;
            }
        },
        async *stream(optionsOrLog) {
            if (isRunning) {
                throw new AgentConcurrencyError('This agent is already running. Create a new agent() instance for concurrent runs.');
            }
            isRunning = true;
            const isSubAgent = builder.__isSubAgent || false;
            const isExplicitSubAgent = builder.__isExplicitSubAgent || false;
            const parentStepIndex = builder.__parentStepIndex;
            const parentTotalSteps = builder.__parentTotalSteps;
            const progress = showProgress ? createProgressHandler(steps.length, isSubAgent, isExplicitSubAgent, parentStepIndex, parentTotalSteps) : null;
            // Parse options for backward compatibility
            let streamOnToken;
            let log;
            if (typeof optionsOrLog === 'function') {
                // Old API: stream(callback)
                log = optionsOrLog;
            }
            else if (optionsOrLog) {
                // New API: stream({ onToken, onStep })
                streamOnToken = optionsOrLog.onToken;
                log = optionsOrLog.onStep;
            }
            // Start agent span
            const agentSpan = telemetry?.startAgentSpan(steps.length) || null;
            const out = [];
            // Capture streamOnToken from stream() context for use in doStep
            const capturedStreamOnToken = streamOnToken;
            try {
                // snapshot steps array to make run isolated from later .then() calls
                const planned = [...steps];
                for (const raw of planned) {
                    if (raw.__reset) {
                        contextHistory = [];
                        continue;
                    }
                    // Handle advanced pattern steps (same as run() with hooks)
                    if (raw.__parallel) {
                        const hooks = raw.__hooks;
                        try {
                            hooks?.pre?.();
                        }
                        catch (e) {
                            console.warn('Pre-hook failed for parallel:', e);
                        }
                        const parallelResult = await executeParallel(raw.__parallel, async (step) => {
                            const subAgent = agent(opts).then(step);
                            const results = await subAgent.run();
                            return results[0];
                        });
                        out.push(parallelResult);
                        contextHistory.push(parallelResult);
                        log?.(parallelResult, out.length - 1);
                        yield parallelResult;
                        try {
                            hooks?.post?.();
                        }
                        catch (e) {
                            console.warn('Post-hook failed for parallel:', e);
                        }
                        continue;
                    }
                    if (raw.__branch) {
                        const { condition, branches } = raw.__branch;
                        const hooks = raw.__hooks;
                        try {
                            hooks?.pre?.();
                        }
                        catch (e) {
                            console.warn('Pre-hook failed for branch:', e);
                        }
                        const branchResults = await executeBranch(condition, branches, out, () => agent(opts));
                        out.push(...branchResults);
                        contextHistory.push(...branchResults);
                        for (const r of branchResults) {
                            log?.(r, out.length - branchResults.length + branchResults.indexOf(r));
                            yield r;
                        }
                        try {
                            hooks?.post?.();
                        }
                        catch (e) {
                            console.warn('Post-hook failed for branch:', e);
                        }
                        continue;
                    }
                    if (raw.__switch) {
                        const { selector, cases } = raw.__switch;
                        const hooks = raw.__hooks;
                        try {
                            hooks?.pre?.();
                        }
                        catch (e) {
                            console.warn('Pre-hook failed for switch:', e);
                        }
                        const switchResults = await executeSwitch(selector, cases, out, () => agent(opts));
                        out.push(...switchResults);
                        contextHistory.push(...switchResults);
                        for (const r of switchResults) {
                            log?.(r, out.length - switchResults.length + switchResults.indexOf(r));
                            yield r;
                        }
                        try {
                            hooks?.post?.();
                        }
                        catch (e) {
                            console.warn('Post-hook failed for switch:', e);
                        }
                        continue;
                    }
                    if (raw.__while) {
                        const { condition, body, opts: whileOpts } = raw.__while;
                        try {
                            whileOpts?.pre?.();
                        }
                        catch (e) {
                            console.warn('Pre-hook failed for while:', e);
                        }
                        const whileResults = await executeWhile(condition, body, out, () => agent(opts), whileOpts);
                        out.push(...whileResults);
                        contextHistory.push(...whileResults);
                        for (const r of whileResults) {
                            log?.(r, out.length - whileResults.length + whileResults.indexOf(r));
                            yield r;
                        }
                        try {
                            whileOpts?.post?.();
                        }
                        catch (e) {
                            console.warn('Post-hook failed for while:', e);
                        }
                        continue;
                    }
                    if (raw.__forEach) {
                        const { items, body } = raw.__forEach;
                        const hooks = raw.__hooks;
                        try {
                            hooks?.pre?.();
                        }
                        catch (e) {
                            console.warn('Pre-hook failed for forEach:', e);
                        }
                        const forEachResults = await executeForEach(items, body, () => agent(opts));
                        out.push(...forEachResults);
                        contextHistory.push(...forEachResults);
                        for (const r of forEachResults) {
                            log?.(r, out.length - forEachResults.length + forEachResults.indexOf(r));
                            yield r;
                        }
                        try {
                            hooks?.post?.();
                        }
                        catch (e) {
                            console.warn('Post-hook failed for forEach:', e);
                        }
                        continue;
                    }
                    if (raw.__retryUntil) {
                        const { body, successCondition, opts: retryOpts } = raw.__retryUntil;
                        try {
                            retryOpts?.pre?.();
                        }
                        catch (e) {
                            console.warn('Pre-hook failed for retryUntil:', e);
                        }
                        const retryResults = await executeRetryUntil(body, successCondition, () => agent(opts), retryOpts);
                        out.push(...retryResults);
                        contextHistory.push(...retryResults);
                        for (const r of retryResults) {
                            log?.(r, out.length - retryResults.length + retryResults.indexOf(r));
                            yield r;
                        }
                        try {
                            retryOpts?.post?.();
                        }
                        catch (e) {
                            console.warn('Post-hook failed for retryUntil:', e);
                        }
                        continue;
                    }
                    if (raw.__runAgent) {
                        const { subAgent } = raw.__runAgent;
                        const hooks = raw.__hooks;
                        try {
                            hooks?.pre?.();
                        }
                        catch (e) {
                            console.warn('Pre-hook failed for runAgent:', e);
                        }
                        const subResults = await executeRunAgent(subAgent, out.length, planned.length);
                        out.push(...subResults);
                        contextHistory.push(...subResults);
                        for (const r of subResults) {
                            log?.(r, out.length - subResults.length + subResults.indexOf(r));
                            yield r;
                        }
                        try {
                            hooks?.post?.();
                        }
                        catch (e) {
                            console.warn('Post-hook failed for runAgent:', e);
                        }
                        continue;
                    }
                    const s = typeof raw === 'function' ? raw(out) : raw;
                    const stepTimeoutMs = s.timeout != null ? s.timeout * 1000 : defaultTimeoutMs; // seconds -> ms
                    const retryCfg = s.retry ?? defaultRetry;
                    const attemptsTotal = typeof retryCfg.retries === 'number' && retryCfg.retries > 0 ? retryCfg.retries : (defaultRetry.retries ?? 3);
                    const useDelay = typeof retryCfg.delay === 'number' ? retryCfg.delay : (defaultRetry.delay ?? 0);
                    const useBackoff = retryCfg.backoff;
                    if (useDelay && useBackoff)
                        throw new Error('retry: specify either delay or backoff, not both');
                    const doStep = async () => {
                        // Execute pre-step hook
                        if (s.pre) {
                            try {
                                s.pre();
                            }
                            catch (e) {
                                console.warn('Pre-step hook failed:', e);
                            }
                        }
                        // Determine step type for telemetry
                        let stepType = 'unknown';
                        if ("agents" in s)
                            stepType = 'agent_crew';
                        else if ("mcps" in s)
                            stepType = 'mcp_auto';
                        else if ("mcp" in s)
                            stepType = 'mcp_explicit';
                        else if ("prompt" in s)
                            stepType = 'llm';
                        // Start step span
                        const stepSpan = telemetry?.startStepSpan(agentSpan, out.length, stepType) || null;
                        const r = {};
                        const stepStart = Date.now();
                        let llmTotalMs = 0;
                        // Automatic tool selection with iterative tool calls
                        if ("mcps" in s && "prompt" in s) {
                            const usedLlm = s.llm ?? defaultLlm;
                            if (!usedLlm)
                                throw new Error("No LLM provided. Pass { llm } to agent(...) or specify per-step.");
                            const stepInstructions = s.instructions ?? globalInstructions;
                            const cmr = s.contextMaxToolResults ?? contextMaxToolResults;
                            const cmc = s.contextMaxChars ?? contextMaxChars;
                            const promptWithHistory = s.prompt + buildHistoryContextChunked(contextHistory, cmr, cmc);
                            r.prompt = s.prompt;
                            // Apply agent-level auth to all MCP handles
                            const mcpsWithAuth = s.mcps.map(applyAgentAuth);
                            const availableTools = await discoverTools(mcpsWithAuth);
                            if (availableTools.length === 0) {
                                r.llmOutput = "No tools available for this request.";
                            }
                            else {
                                const aggregated = [];
                                const maxIterations = s.maxToolIterations ?? defaultMaxToolIterations;
                                let workingPrompt = (stepInstructions ? stepInstructions + "\n\n" : "") + promptWithHistory;
                                for (let i = 0; i < maxIterations; i++) {
                                    const llmStart = Date.now();
                                    let toolPlan;
                                    try {
                                        toolPlan = await usedLlm.genWithTools(workingPrompt, availableTools);
                                    }
                                    catch (e) {
                                        const provider = classifyProviderFromLlm(usedLlm);
                                        throw normalizeError(e, 'llm', { stepId: out.length, provider });
                                    }
                                    llmTotalMs += Date.now() - llmStart;
                                    if (!toolPlan || !Array.isArray(toolPlan.toolCalls) || toolPlan.toolCalls.length === 0) {
                                        // finish with final content
                                        r.llmOutput = toolPlan?.content || r.llmOutput;
                                        break;
                                    }
                                    // Execute tools sequentially and append results to prompt for the next iteration
                                    let toolResultsAppend = "\n\n[Tool results]\n";
                                    for (const call of toolPlan.toolCalls) {
                                        const mapped = call;
                                        let handle = mapped?.mcpHandle;
                                        if (!handle)
                                            continue;
                                        // Apply agent-level auth
                                        handle = applyAgentAuth(handle);
                                        // Validate args when schema known
                                        try {
                                            validateWithSchema(availableTools.find(t => t.name === mapped.name)?.parameters, mapped.arguments, `Tool ${mapped.name}`);
                                        }
                                        catch (e) {
                                            throw e;
                                        }
                                        const idx = mapped.name.indexOf('.');
                                        const actualToolName = idx >= 0 ? mapped.name.slice(idx + 1) : mapped.name;
                                        const mcpStart = Date.now();
                                        let result;
                                        try {
                                            result = await withMCP(handle, (c) => c.callTool({ name: actualToolName, arguments: mapped.arguments || {} }), telemetry, 'call_tool');
                                        }
                                        catch (e) {
                                            const provider = classifyProviderFromMcp(handle);
                                            throw normalizeError(e, 'mcp-tool', { stepId: out.length, provider });
                                        }
                                        const mcpMs = Date.now() - mcpStart;
                                        const toolCall = { name: mapped.name, arguments: mapped.arguments, endpoint: handle.url, result, ms: mcpMs };
                                        aggregated.push(toolCall);
                                        toolResultsAppend += `- ${mapped.name} -> ${typeof result === 'string' ? result : JSON.stringify(result)}\n`;
                                    }
                                    if (aggregated.length)
                                        r.toolCalls = aggregated;
                                    // Prepare next prompt with appended tool results
                                    workingPrompt = (stepInstructions ? stepInstructions + "\n\n" : "") + promptWithHistory + toolResultsAppend;
                                    // On next iteration, model can produce final answer or ask for more tools
                                }
                                // Ensure toolCalls is always set for automatic tool selection steps
                                if (!r.toolCalls)
                                    r.toolCalls = [];
                            }
                        }
                        // Automatic agent selection with iterative delegation
                        else if ("agents" in s && "prompt" in s) {
                            const usedLlm = s.llm ?? defaultLlm;
                            if (!usedLlm)
                                throw new Error("No LLM provided. Pass { llm } to agent(...) or specify per-step.");
                            const stepInstructions = s.instructions ?? globalInstructions;
                            const cmr = s.contextMaxToolResults ?? contextMaxToolResults;
                            const cmc = s.contextMaxChars ?? contextMaxChars;
                            const promptWithHistory = s.prompt + buildHistoryContextChunked(contextHistory, cmr, cmc);
                            r.prompt = s.prompt;
                            const availableAgents = s.agents;
                            if (availableAgents.length === 0 || !availableAgents.some(a => a.name && a.description)) {
                                r.llmOutput = "No agents available or agents missing name/description.";
                            }
                            else {
                                const agentContext = buildAgentContext(availableAgents);
                                const maxIterations = s.maxAgentIterations ?? defaultMaxToolIterations;
                                let workingPrompt = (stepInstructions ? stepInstructions + "\n\n" : "") + promptWithHistory + agentContext;
                                const agentCalls = [];
                                let totalTokens = 0;
                                const modelsUsed = new Set();
                                for (let i = 0; i < maxIterations; i++) {
                                    // Show coordinator thinking
                                    if (progress) {
                                        if (i === 0) {
                                            process.stdout.write('\n🧠 Coordinator selecting agents...\n');
                                            process.stdout.write("   ⏳ Waiting for LLM..");
                                        }
                                        else {
                                            process.stdout.write('🧠 Coordinator deciding next step...\n');
                                            process.stdout.write("   ⏳ Waiting for LLM..");
                                        }
                                        progress.startLlmOperation();
                                    }
                                    const llmStart = Date.now();
                                    let coordinatorResponse;
                                    let coordTokenCount = 0;
                                    try {
                                        // Use streaming for coordinator when progress enabled
                                        if (progress && typeof usedLlm.genStream === 'function') {
                                            const tokens = [];
                                            for await (const token of usedLlm.genStream(workingPrompt)) {
                                                tokens.push(token);
                                                coordTokenCount++;
                                                progress.llmToken(coordTokenCount, usedLlm.id || usedLlm.model);
                                            }
                                            coordinatorResponse = tokens.join('');
                                        }
                                        else {
                                            coordinatorResponse = await usedLlm.gen(workingPrompt);
                                        }
                                    }
                                    catch (e) {
                                        const provider = classifyProviderFromLlm(usedLlm);
                                        throw normalizeError(e, 'llm', { stepId: out.length, provider });
                                    }
                                    llmTotalMs += Date.now() - llmStart;
                                    const decision = parseAgentDecision(coordinatorResponse);
                                    if (decision.type === 'done') {
                                        totalTokens += coordTokenCount;
                                        modelsUsed.add(usedLlm.id || usedLlm.model);
                                        if (progress) {
                                            const coordTime = (Date.now() - llmStart) / 1000;
                                            // Clear token line and coordinator status line, then print decision
                                            process.stdout.write('\r\x1b[K'); // Clear token line
                                            process.stdout.write('\x1b[1A\r\x1b[K'); // Move up and clear coordinator status line
                                            if (i === 0) {
                                                process.stdout.write('🧠 Coordinator: Final answer ready\n');
                                            }
                                            else {
                                                process.stdout.write('🧠 Coordinator: Final answer ready\n');
                                            }
                                            process.stdout.write(`   ✅ Complete | ${coordTokenCount} tokens | ${coordTime.toFixed(1)}s | ${usedLlm.id || usedLlm.model}\n`);
                                        }
                                        r.llmOutput = decision.answer;
                                        break;
                                    }
                                    else if (decision.type === 'use_agent') {
                                        totalTokens += coordTokenCount;
                                        modelsUsed.add(usedLlm.id || usedLlm.model);
                                        if (progress) {
                                            const coordTime = (Date.now() - llmStart) / 1000;
                                            // Clear token line and coordinator status line, then print decision
                                            process.stdout.write('\r\x1b[K'); // Clear token line
                                            process.stdout.write('\x1b[1A\r\x1b[K'); // Move up and clear coordinator status line
                                            if (i === 0) {
                                                process.stdout.write(`🧠 Coordinator decision: USE ${decision.agentName}\n`);
                                            }
                                            else {
                                                process.stdout.write(`🧠 Coordinator decision: USE ${decision.agentName}\n`);
                                            }
                                            process.stdout.write(`   ✅ Complete | ${coordTokenCount} tokens | ${coordTime.toFixed(1)}s | ${usedLlm.id || usedLlm.model}\n`);
                                        }
                                        const selectedAgent = availableAgents.find(a => a.name === decision.agentName);
                                        if (!selectedAgent) {
                                            workingPrompt += `\n\nError: Agent '${decision.agentName}' not found. Available: ${availableAgents.map(a => a.name).join(', ')}`;
                                            continue;
                                        }
                                        if (progress)
                                            progress.agentStart(decision.agentName, decision.task);
                                        const agentStart = Date.now();
                                        let agentResult;
                                        let agentTokenCount = 0;
                                        try {
                                            // Pass onToken to agent for progress tracking
                                            const agentStep = { prompt: decision.task };
                                            if (progress) {
                                                agentStep.onToken = () => {
                                                    agentTokenCount++;
                                                    progress.agentToken(agentTokenCount, decision.agentName);
                                                };
                                            }
                                            // Mark delegated agent as sub-agent to suppress its progress banner
                                            const delegatedAgent = selectedAgent.then(agentStep);
                                            delegatedAgent.__isSubAgent = true;
                                            agentResult = await delegatedAgent.run();
                                        }
                                        catch (e) {
                                            workingPrompt += `\n\nAgent '${decision.agentName}' failed: ${e.message}`;
                                            continue;
                                        }
                                        const agentMs = Date.now() - agentStart;
                                        totalTokens += agentTokenCount;
                                        modelsUsed.add(usedLlm.id || usedLlm.model);
                                        const agentOutput = agentResult[agentResult.length - 1]?.llmOutput || '[no output]';
                                        agentCalls.push({ name: decision.agentName, task: decision.task, result: agentOutput });
                                        if (progress)
                                            progress.agentComplete(decision.agentName, agentTokenCount, agentMs, usedLlm.id || usedLlm.model);
                                        workingPrompt += `\n\nAgent '${decision.agentName}' completed (${agentMs}ms):\n${agentOutput}\n\nWhat's next?`;
                                    }
                                    else {
                                        if (i === maxIterations - 1) {
                                            r.llmOutput = decision.raw;
                                        }
                                        else {
                                            workingPrompt += `\n\nPlease use the USE or DONE directive.`;
                                        }
                                    }
                                }
                                if (!r.llmOutput && agentCalls.length > 0) {
                                    r.llmOutput = agentCalls[agentCalls.length - 1].result;
                                }
                                if (agentCalls.length > 0) {
                                    r.agentCalls = agentCalls;
                                    r.__crewTotalTokens = totalTokens;
                                    r.__crewModels = Array.from(modelsUsed);
                                    telemetry?.recordMetric('agent.delegation', agentCalls.length, { agents: agentCalls.map(c => c.name).join(',') });
                                    for (const agentCall of agentCalls) {
                                        telemetry?.recordMetric('agent.call', 1, { agentName: agentCall.name });
                                    }
                                }
                            }
                        }
                        // LLM-only steps
                        else if ("prompt" in s && !("mcp" in s) && !("mcps" in s) && !("agents" in s)) {
                            const usedLlm = s.llm ?? defaultLlm;
                            if (!usedLlm)
                                throw new Error("No LLM provided. Pass { llm } to agent(...) or specify per-step.");
                            const stepInstructions = s.instructions ?? globalInstructions;
                            const cmr2 = s.contextMaxToolResults ?? contextMaxToolResults;
                            const cmc2 = s.contextMaxChars ?? contextMaxChars;
                            const promptWithHistory = s.prompt + buildHistoryContextChunked(contextHistory, cmr2, cmc2);
                            const finalPrompt = (stepInstructions ? stepInstructions + "\n\n" : "") + promptWithHistory;
                            r.prompt = s.prompt;
                            const llmSpan = telemetry?.startLLMSpan(stepSpan, usedLlm, finalPrompt) || null;
                            const llmStart = Date.now();
                            try {
                                r.llmOutput = await executeLLMWithStreaming(usedLlm, finalPrompt, s.onToken, capturedStreamOnToken, { stepIndex: out.length, stepPrompt: s.prompt });
                                telemetry?.endSpan(llmSpan);
                                telemetry?.recordMetric('llm.call', 1, { provider: usedLlm.id || usedLlm.model, error: false });
                            }
                            catch (e) {
                                telemetry?.endSpan(llmSpan, undefined, e);
                                telemetry?.recordMetric('llm.call', 1, { provider: usedLlm.id || usedLlm.model, error: true });
                                telemetry?.recordMetric('error', 1, { type: 'llm', provider: usedLlm.id || usedLlm.model });
                                const provider = classifyProviderFromLlm(usedLlm);
                                throw normalizeError(e, 'llm', { stepId: out.length, provider });
                            }
                            llmTotalMs += Date.now() - llmStart;
                        }
                        // Explicit MCP tool calls (existing behavior)
                        else if ("mcp" in s && "tool" in s) {
                            // Apply agent-level auth
                            const mcpHandle = applyAgentAuth(s.mcp);
                            if ("prompt" in s) {
                                const usedLlm = s.llm ?? defaultLlm;
                                if (!usedLlm)
                                    throw new Error("No LLM provided. Pass { llm } to agent(...) or specify per-step.");
                                const stepInstructions = s.instructions ?? globalInstructions;
                                const cmr3 = s.contextMaxToolResults ?? contextMaxToolResults;
                                const cmc3 = s.contextMaxChars ?? contextMaxChars;
                                const promptWithHistory = s.prompt + buildHistoryContextChunked(contextHistory, cmr3, cmc3);
                                const finalPrompt = (stepInstructions ? stepInstructions + "\n\n" : "") + promptWithHistory;
                                r.prompt = s.prompt;
                                const llmStart = Date.now();
                                r.llmOutput = await usedLlm.gen(finalPrompt);
                                llmTotalMs += Date.now() - llmStart;
                            }
                            // Validate against tool schema if discoverable
                            const schema = await getToolSchema(mcpHandle, s.tool);
                            validateWithSchema(schema, s.args ?? {}, `Tool ${mcpHandle.id}.${s.tool}`);
                            const mcpStart = Date.now();
                            let res;
                            try {
                                res = await withMCP(mcpHandle, (c) => c.callTool({ name: s.tool, arguments: s.args ?? {} }), telemetry, 'call_tool');
                            }
                            catch (e) {
                                const provider = classifyProviderFromMcp(mcpHandle);
                                throw normalizeError(e, 'mcp-tool', { stepId: out.length, provider });
                            }
                            const mcpMs = Date.now() - mcpStart;
                            r.mcp = { endpoint: mcpHandle.url, tool: s.tool, result: res, ms: mcpMs };
                        }
                        r.llmMs = llmTotalMs;
                        r.durationMs = Date.now() - stepStart;
                        // End step span
                        telemetry?.endSpan(stepSpan, r);
                        telemetry?.recordMetric('step.duration', r.durationMs, { type: stepType });
                        // Execute post-step hook
                        if (s.post) {
                            try {
                                s.post();
                            }
                            catch (e) {
                                console.warn('Post-step hook failed:', e);
                            }
                        }
                        return r;
                    };
                    // Retry loop with per-attempt timeout
                    let lastError;
                    let result;
                    for (let attempt = 1; attempt <= attemptsTotal; attempt++) {
                        try {
                            const r = await withTimeout(doStep(), stepTimeoutMs, 'Step');
                            result = r;
                            break;
                        }
                        catch (e) {
                            // classify
                            const meta = { stepId: out.length };
                            let vErr;
                            if (e instanceof Error && /timed out/i.test(e.message)) {
                                vErr = normalizeError(e, 'timeout', meta);
                            }
                            else if (e instanceof ValidationError || /failed schema validation/i.test(String(e?.message || ''))) {
                                vErr = normalizeError(e, 'validation', meta);
                            }
                            else {
                                vErr = e;
                            }
                            lastError = vErr || e;
                            if (lastError instanceof VolcanoError && lastError.meta?.retryable === false) {
                                throw lastError; // abort retries immediately for non-retryable errors
                            }
                            if (attempt >= attemptsTotal)
                                break;
                            // schedule wait according to policy
                            if (typeof useBackoff === 'number' && useBackoff > 0) {
                                const baseMs = 1000; // start at 1s
                                const waitMs = baseMs * Math.pow(useBackoff, attempt - 1);
                                await sleep(waitMs);
                            }
                            else {
                                const waitMs = Math.max(0, (useDelay ?? 0) * 1000);
                                if (waitMs > 0)
                                    await sleep(waitMs);
                            }
                        }
                    }
                    if (!result)
                        throw (lastError instanceof VolcanoError ? lastError : new RetryExhaustedError('Retry attempts exhausted', { stepId: out.length }, { cause: lastError }));
                    const r = result;
                    log?.(r, out.length);
                    out.push(r);
                    contextHistory.push(r);
                    // Yield the step result for streaming
                    yield r;
                }
                // Note: We don't populate aggregated totals for streaming since it's incremental
            }
            finally {
                if (progress) {
                    // Calculate totals for workflow end
                    const totalTokens = out.reduce((acc, s) => {
                        const stepTokens = s.__tokenCount || s.__crewTotalTokens || 0;
                        return acc + stepTokens;
                    }, 0);
                    const modelsUsed = new Set();
                    out.forEach(s => {
                        const provider = s.__provider;
                        const crewModels = s.__crewModels;
                        if (provider)
                            modelsUsed.add(provider);
                        if (crewModels)
                            crewModels.forEach((m) => modelsUsed.add(m));
                    });
                    const totalDuration = out.reduce((acc, s) => acc + (s.durationMs || 0), 0);
                    progress.workflowEnd(steps.length, totalTokens, totalDuration, Array.from(modelsUsed));
                }
                isRunning = false;
            }
        },
    };
    return builder;
}
